{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T16:06:55.074106Z",
     "start_time": "2019-09-18T16:06:52.689111Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ta\n",
    "# from fastai import *\n",
    "# from fastai.tabular import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from rolling import RollingWindowSplit\n",
    "from sklearn.metrics import r2_score as r2d2\n",
    "from joblib import dump, load\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style = \"whitegrid\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:35:09.752232Z",
     "start_time": "2019-09-18T15:35:09.747232Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# path = 'D://Coding//XTX Forecasting Challenge//data-training.csv'\n",
    "# df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T16:07:02.528106Z",
     "start_time": "2019-09-18T16:06:55.077109Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'D://Coding//XTX Forecasting Challenge//data-training.file'\n",
    "df = pd.read_feather(path, use_threads=8)\n",
    "df = df.astype('float32')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T16:07:02.541111Z",
     "start_time": "2019-09-18T16:07:02.531107Z"
    }
   },
   "outputs": [],
   "source": [
    "bidSizeList = ['bidSize' + str(i) for i in range(0,15)]\n",
    "askSizeList = ['askSize' + str(i) for i in range(0,15)]\n",
    "bidRateList = ['bidRate' + str(i) for i in range(0,15)]\n",
    "askRateList = ['askRate' + str(i) for i in range(0,15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:01:58.506630Z",
     "start_time": "2019-09-18T03:01:58.500630Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Figuring out what [y] is\n",
    "# # y(t) is midRate(t+87) - midRate(t), clipped to (-5.5)\n",
    "# df['expectedY'] = df.midRate.diff(87).shift(-87).clip(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-sectional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T09:22:15.171584Z",
     "start_time": "2019-09-18T09:22:09.201585Z"
    }
   },
   "outputs": [],
   "source": [
    "# different from submission\n",
    "def compute_cross_sectional(df):\n",
    "#     df = pd.DataFrame([base_row])\n",
    "#     df.columns = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]\n",
    "\n",
    "    # Cross-sectional features\n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['midRate'] = (df.askRate0 + df.bidRate0) / 2\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['totalBidVol1'] = df.bidSize0 + df.bidSize1\n",
    "    df['totalAskVol1'] = df.askSize0 + df.askSize1\n",
    "    for i in range(2,15):\n",
    "        df['totalBidVol' + str(i)] = df['totalBidVol' + str(i-1)] + df['bidSize' + str(i)]\n",
    "        df['totalAskVol' + str(i)] = df['totalAskVol' + str(i-1)] + df['askSize' + str(i)]\n",
    "    for i in range(1,15):\n",
    "        df['bidAskRatio' + str(i)] = df['totalBidVol' + str(i)] / df['totalAskVol' + str(i)]\n",
    "    df['totalAvailVol'] = df.totalBidVol14 + df.totalAskVol14\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    return df\n",
    "df = compute_cross_sectional(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T09:23:08.352461Z",
     "start_time": "2019-09-18T09:23:05.873467Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    b1, a1 = (df.bidRate0 < df.bidRate0.shift(1)), (df.askRate0 < df.askRate0.shift(1))\n",
    "    b2, a2 = (df.bidRate0 == df.bidRate0.shift(1)), (df.askRate0 == df.askRate0.shift(1))\n",
    "    valsB, valsA = [0, (df.bidSize0 - df.bidSize0.shift(1))], [0, (df.askSize0 - df.askSize0.shift(1))]\n",
    "    defaultB, defaultA = df.bidSize0, df.askSize0\n",
    "    df.fillna(0, inplace=True)\n",
    "    df['deltaVBid'] = np.select([b1,b2], valsB, default=defaultB)\n",
    "    df['deltaVAsk'] = np.select([a1,a2], valsA, default=defaultA)\n",
    "    df['VOI'] = df.deltaVBid - df.deltaVAsk\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    return df\n",
    "df = add_time_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:02:06.650630Z",
     "start_time": "2019-09-18T03:02:06.646626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Requires a window of up to a 1000 past items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual time features â€” can consider adding more to the lags list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T09:24:32.846650Z",
     "start_time": "2019-09-18T09:24:27.397616Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_manual_time_features(df):\n",
    "    lags = [*np.arange(1,10), *np.arange(10,100,10), *np.arange(100,1000,100)]\n",
    "    def addTimeFeatures(i):\n",
    "        df['daskRate' + str(i)] = df.askRate0.diff(i)\n",
    "        df['dbidRate' + str(i)] = df.bidRate0.diff(i)\n",
    "    for i in lags:\n",
    "        addTimeFeatures(i)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "df = add_manual_time_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:02:19.677474Z",
     "start_time": "2019-09-18T03:02:14.847627Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_feather('intermediate.file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:35:26.394218Z",
     "start_time": "2019-09-18T15:35:17.569033Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_feather('intermediate.file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tick chart version with ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:02:20.113471Z",
     "start_time": "2019-09-18T03:02:19.680475Z"
    }
   },
   "outputs": [],
   "source": [
    "# midrate version\n",
    "df['time'] = pd.date_range(start='1/1/1970', periods=2999999, freq='T')\n",
    "df.set_index('time', inplace=True)\n",
    "df_mid = df.midRate.resample('15Min').ohlc()\n",
    "df_mid['vol'] = df.bidAskVol.resample('15Min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:06:35.616471Z",
     "start_time": "2019-09-18T03:02:24.330407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tym\\Miniconda3\\envs\\working\\lib\\site-packages\\ta\\trend.py:170: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dip[i] = 100 * (dip_mio[i]/trs[i])\n",
      "C:\\Users\\Tym\\Miniconda3\\envs\\working\\lib\\site-packages\\ta\\trend.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (dip_mio[i]/trs[i])\n",
      "C:\\Users\\Tym\\Miniconda3\\envs\\working\\lib\\site-packages\\ta\\trend.py:174: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  din[i] = 100 * (din_mio[i]/trs[i])\n",
      "C:\\Users\\Tym\\Miniconda3\\envs\\working\\lib\\site-packages\\ta\\trend.py:174: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (din_mio[i]/trs[i])\n",
      "C:\\Users\\Tym\\Miniconda3\\envs\\working\\lib\\site-packages\\ta\\trend.py:176: RuntimeWarning: invalid value encountered in subtract\n",
      "  dx = 100 * np.abs((dip - din) / (dip + din))\n"
     ]
    }
   ],
   "source": [
    "# takes 5 min\n",
    "df_mid_ta = ta.add_all_ta_features(df_mid, \"open\", \"high\", \"low\", \"close\", \"vol\", fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T09:25:48.213817Z",
     "start_time": "2019-09-18T09:25:47.644693Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump(df_mid_ta, 'df_mid_ta.joblib')\n",
    "df_mid_ta = load('df_mid_ta.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T09:15:36.003137Z",
     "start_time": "2019-09-18T09:15:35.994137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.8970764e+01,  1.8328373e+01, -1.9263544e+01, -1.5587357e+01,\n",
       "        -4.7632145e+01,  5.3526089e+01,  1.2909327e+01, -1.8256685e+01,\n",
       "         3.6211021e+00, -1.5878495e+01,  2.5628702e+02, -2.4331863e+01,\n",
       "         4.8973980e+00,  1.8533689e-01,  2.0022793e+01,  3.3933430e+01,\n",
       "         9.8881996e+01, -3.3170212e+01,  1.0228539e+02,  4.5066171e+00,\n",
       "        -2.8165766e+01, -8.9614071e-02, -1.1391719e+01, -1.1329915e+01,\n",
       "         1.7320482e+01, -1.0655308e+01, -5.4672961e+00,  2.3649971e+01,\n",
       "        -2.2624979e+01, -2.9913643e+01, -5.1912155e+00,  3.9424671e+01,\n",
       "        -1.1298305e+01, -4.6017570e+00, -2.1380127e+01,  1.8141096e+01,\n",
       "        -5.3065324e+00,  1.2948828e+01, -1.2238501e+01,  6.9587070e-01,\n",
       "        -4.0120945e+00,  5.1201946e-01,  1.0402673e+01, -1.2824577e+01,\n",
       "         9.7495251e+00, -6.7554579e+00,  3.2993751e+00,  1.9961107e+01,\n",
       "         3.2359062e+01, -7.7225599e+00]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:07:17.706451Z",
     "start_time": "2019-09-18T03:06:35.912455Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 30s\n",
    "new_df = df.join(df_mid_ta).ffill()\n",
    "new_df = new_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T16:07:16.817106Z",
     "start_time": "2019-09-18T16:07:02.674108Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump(new_df, 'new_df.joblib')\n",
    "new_df = load('new_df.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out a way to validate the blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:41:19.160683Z",
     "start_time": "2019-09-18T15:41:17.390685Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df.drop([*askRateList, *askSizeList, *bidRateList, *bidSizeList], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:41:54.181073Z",
     "start_time": "2019-09-18T15:41:30.991562Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 40s\n",
    "X = new_df.drop('y', axis=1).values\n",
    "y = new_df.y.values\n",
    "\n",
    "# standardise\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:42:42.962012Z",
     "start_time": "2019-09-18T15:41:54.192080Z"
    }
   },
   "outputs": [],
   "source": [
    "# pca takes 1 min\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:42:43.045008Z",
     "start_time": "2019-09-18T15:42:42.969004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_drop.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(scaler, 'scaler_drop.joblib')\n",
    "dump(pca, 'pca_drop.joblib')\n",
    "# X_pca = load('X_pca.joblib')\n",
    "# y = load('y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T06:00:51.539564Z",
     "start_time": "2019-09-15T06:00:51.536553Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:42:43.062007Z",
     "start_time": "2019-09-18T15:42:43.048008Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcv = RollingWindowSplit(n_splits=5, compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:43:35.796674Z",
     "start_time": "2019-09-18T15:42:43.065004Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes at least 1 min on pca variables\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "lasso = LassoLarsCV(cv=rlcv, n_jobs=-1).fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually the lasso above has seen the entire dataset...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:43:35.843679Z",
     "start_time": "2019-09-18T15:43:35.807676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lassocv_drop.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lasso, 'lassocv_drop.joblib')\n",
    "# lasso = load('lassocv.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:17:35.966981Z",
     "start_time": "2019-09-18T03:17:35.929979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True,\n",
       "            cv=RollingWindowSplit(compatible=True, max_train_size=None, n_splits=5),\n",
       "            eps=2.220446049250313e-16, fit_intercept=True, max_iter=500,\n",
       "            max_n_alphas=1000, n_jobs=-1, normalize=True, positive=False,\n",
       "            precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:43:36.018674Z",
     "start_time": "2019-09-18T15:43:35.849677Z"
    }
   },
   "outputs": [],
   "source": [
    "def rlcvscore(model):\n",
    "    cvtrain, cvvalid, cvvalidsig = [], [], []\n",
    "    for inc, (train_index, valid_index) in enumerate(rlcv.split(X_pca), 1):\n",
    "        x_train, x_valid = X_pca[train_index], X_pca[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        cvtrain.append(model.score(x_train, y_train))\n",
    "        cvvalid.append(model.score(x_valid, y_valid))\n",
    "        sigmoid = (1/(1+np.exp(-0.22*model.predict(x_valid)))-0.5)*20  \n",
    "        cvvalidsig.append(r2d2(y_valid, sigmoid))\n",
    "    print(f'{np.array(cvtrain).round(4)}')\n",
    "    print(f'{np.array(cvvalid).round(4)}')\n",
    "    print(f'{np.array(cvvalidsig).round(4)}')\n",
    "    print(f'{np.mean(cvtrain):.4f}, {np.mean(cvvalid):.4f}, {np.mean(cvvalidsig):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T15:43:40.721679Z",
     "start_time": "2019-09-18T15:43:36.024680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0479 0.0557 0.0582 0.0557 0.0553]\n",
      "[0.0557 0.0582 0.0557 0.0553 0.0569]\n",
      "[0.0581 0.0609 0.058  0.0574 0.0585]\n",
      "0.0546, 0.0564, 0.0586\n"
     ]
    }
   ],
   "source": [
    "rlcvscore(lasso) # dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:10:15.772998Z",
     "start_time": "2019-09-18T03:10:10.483029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0304 0.0465 0.0495 0.05   0.0484]\n",
      "[0.0465 0.0495 0.05   0.0484 0.047 ]\n",
      "[0.049  0.0522 0.0526 0.0507 0.0485]\n",
      "0.0449, 0.0483, 0.0506\n"
     ]
    }
   ],
   "source": [
    "rlcvscore(lasso) # undropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T05:59:31.740319Z",
     "start_time": "2019-09-15T05:59:31.737316Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump(lasso, f'lasso_rlcv_114ft_0.0175_0.0187.joblib')\n",
    "# lasso = load('lasso_rlcv_114ft_0.0175_0.0187.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:41:51.898791Z",
     "start_time": "2019-09-15T02:41:46.090168Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=10, max_depth=6, min_samples_split=1000, min_samples_leaf=1000,\n",
    "                                 max_features='auto', n_jobs=-1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:41:51.898791Z",
     "start_time": "2019-09-15T02:41:46.090168Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:23:41.727016Z",
     "start_time": "2019-09-15T02:23:36.056348Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcvscore(rf_model) # realistic cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:29:21.674236Z",
     "start_time": "2019-09-15T02:29:20.651235Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df.drop('y', axis=1).columns[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:42:44.365273Z",
     "start_time": "2019-09-15T02:42:43.164275Z"
    }
   },
   "outputs": [],
   "source": [
    "# create X with important variables only\n",
    "X = df.drop('y', axis=1)[a[:20]].values\n",
    "y = df.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:47:05.341074Z",
     "start_time": "2019-09-15T02:47:05.336062Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=10, max_depth=2, min_samples_split=2, min_samples_leaf=5000,\n",
    "                                 max_features='auto', n_jobs=-1, random_state=41)\n",
    "rf_model.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:47:12.600562Z",
     "start_time": "2019-09-15T02:47:10.741562Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcvscore(rf_model) #n_est 10, depth 2, samples_split 2, samples_leaf 1000, 30 most importantvariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T02:24:45.787782Z",
     "start_time": "2019-09-15T02:24:41.788297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "dump(rf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rf2 = load('model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:34:27.199966Z",
     "start_time": "2019-09-13T08:34:27.194964Z"
    }
   },
   "outputs": [],
   "source": [
    "dep_var = 'y'\n",
    "procs = [FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:34:46.357867Z",
     "start_time": "2019-09-13T08:34:29.653867Z"
    }
   },
   "outputs": [],
   "source": [
    "path = f'D:\\Coding\\XTX Forecasting Challenge'\n",
    "data = TabularDataBunch.from_df(path = path, df = df[:int(5e5)], dep_var = 'y', procs=procs,\n",
    "                                 valid_idx = list(range(int(4e5),int(5e5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:26:47.618579Z",
     "start_time": "2019-09-13T08:26:17.525620Z"
    }
   },
   "outputs": [],
   "source": [
    "data.show_batch(rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T06:27:39.484687Z",
     "start_time": "2019-09-13T06:27:21.410885Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = (TabularList.from_df(df[:int(5e5)], cont_names=df.columns, procs=procs)\n",
    "#                            .split_by_idx(list(range(int(0.8*5e5),int(5e5))))\n",
    "#                            .label_from_df(cols=dep_var, label_cls=FloatList)\n",
    "#                            .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:50:44.246393Z",
     "start_time": "2019-09-13T08:50:44.024206Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[500,200], metrics=r2_score, ps=[0.001,0.01], emb_drop=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:50:45.534954Z",
     "start_time": "2019-09-13T08:50:45.527952Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:37:03.605733Z",
     "start_time": "2019-09-13T08:36:35.900238Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find(end_lr=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:37:04.843812Z",
     "start_time": "2019-09-13T08:37:03.608733Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model above has already diverged, we will restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:03:36.738452Z",
     "start_time": "2019-09-13T08:50:49.724470Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 1e-4, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T08:41:02.673928Z",
     "start_time": "2019-09-13T08:41:01.868908Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:04:03.690828Z",
     "start_time": "2019-09-13T09:04:03.447302Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('new_fastai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:04:07.023062Z",
     "start_time": "2019-09-13T09:04:06.385055Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:05:00.282946Z",
     "start_time": "2019-09-13T09:05:00.098945Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[int(8.1e5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:05:02.937494Z",
     "start_time": "2019-09-13T09:05:02.932488Z"
    }
   },
   "outputs": [],
   "source": [
    "df.y.iloc[int(8.1e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T09:05:38.921082Z",
     "start_time": "2019-09-13T09:05:08.529113Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T02:41:30.938305Z",
     "start_time": "2019-09-18T02:41:30.934301Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_data_as_numpy_array(iteration):\n",
    "    return df.iloc[iteration][:60].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T01:06:52.643644Z",
     "start_time": "2019-09-18T01:06:52.637642Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_to_df(massive_df, row):\n",
    "    try: row.index = [massive_df.index[-1] + timedelta(minutes=1)]\n",
    "    except: row.index = [datetime(1970,1,1)]\n",
    "    return massive_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T01:54:23.276600Z",
     "start_time": "2019-09-18T01:54:23.264625Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_resample_features(massive_df, resampled_df):\n",
    "    leftovers = len(massive_df) % 15\n",
    "    a = pd.DataFrame()\n",
    "    def pad_history():\n",
    "        full_resampled = resampled_df.append(df_mid)\n",
    "        a = pd.DataFrame([full_resampled.iloc[0] for j in range(30+1-len(full_resampled))])\n",
    "        a = a.append(full_resampled)\n",
    "        a.index = pd.date_range(start=df_mid.index[-1], periods=len(a), freq='-15Min').sort_values()\n",
    "        df_mid_ta = ta.add_all_ta_features(a, \"open\", \"high\", \"low\", \"close\", \"vol\", fillna=True)\n",
    "        return df_mid_ta\n",
    "    if leftovers == 0:\n",
    "        df_mid = massive_df.tail(15).midRate.resample('15Min').ohlc()\n",
    "        df_mid['vol'] = massive_df.tail(15).bidAskVol.resample('15Min').mean()\n",
    "        df_mid_ta = pad_history()\n",
    "        resampled_df = resampled_df.append(df_mid_ta)\n",
    "    else:\n",
    "        df_mid = massive_df.tail(leftovers).midRate.resample('15Min').ohlc()\n",
    "        df_mid['vol'] = massive_df.tail(leftovers).bidAskVol.resample('15Min').mean()\n",
    "        df_mid_ta = pad_history()\n",
    "    massive_df.update(df_mid_ta)\n",
    "    massive_df = massive_df.ffill().astype('float32')\n",
    "    return massive_df, resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T02:44:37.474922Z",
     "start_time": "2019-09-18T02:44:37.470926Z"
    }
   },
   "outputs": [],
   "source": [
    "massive_df, resampled_df = pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T00:45:54.723668Z",
     "start_time": "2019-09-18T00:45:54.702671Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cross_sectional(base_row):\n",
    "    df = pd.DataFrame([base_row])\n",
    "    df.columns = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]\n",
    "\n",
    "    # Cross-sectional features\n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['midRate'] = (df.askRate0 + df.bidRate0) / 2\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['totalBidVol1'] = df.bidSize0 + df.bidSize1\n",
    "    df['totalAskVol1'] = df.askSize0 + df.askSize1\n",
    "    for i in range(2,15):\n",
    "        df['totalBidVol' + str(i)] = df['totalBidVol' + str(i-1)] + df['bidSize' + str(i)]\n",
    "        df['totalAskVol' + str(i)] = df['totalAskVol' + str(i-1)] + df['askSize' + str(i)]\n",
    "    for i in range(1,15):\n",
    "        df['bidAskRatio' + str(i)] = df['totalBidVol' + str(i)] / df['totalAskVol' + str(i)]\n",
    "    df['totalAvailVol'] = df.totalBidVol14 + df.totalAskVol14\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T02:44:49.748429Z",
     "start_time": "2019-09-18T02:44:38.351308Z"
    }
   },
   "outputs": [],
   "source": [
    "for iteration in range(30):\n",
    "    base_row = get_next_data_as_numpy_array(len(massive_df))\n",
    "    row = compute_cross_sectional(base_row)\n",
    "    massive_df = append_to_df(massive_df, row)\n",
    "    massive_df, resampled_df = add_resample_features(massive_df, resampled_df)\n",
    "    massive_df = add_time_features(massive_df)\n",
    "    massive_df = add_manual_time_features(massive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T02:31:40.456053Z",
     "start_time": "2019-09-18T02:31:40.441056Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    b1, a1 = (df.bidRate0 < df.bidRate0.shift(1)), (df.askRate0 < df.askRate0.shift(1))\n",
    "    b2, a2 = (df.bidRate0 == df.bidRate0.shift(1)), (df.askRate0 == df.askRate0.shift(1))\n",
    "#     print(b1,a1,b2,a2)\n",
    "    valsB, valsA = [0, (df.bidSize0 - df.bidSize0.shift(1))], [0, (df.askSize0 - df.askSize0.shift(1))]\n",
    "    defaultB, defaultA = df.bidSize0, df.askSize0\n",
    "    df.fillna(0, inplace=True)    \n",
    "    df['deltaVBid'] = np.select([b1,b2], valsB, default=defaultB)\n",
    "    df['deltaVAsk'] = np.select([a1,a2], valsA, default=defaultA)\n",
    "    df['VOI'] = df.deltaVBid - df.deltaVAsk\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T01:06:55.989315Z",
     "start_time": "2019-09-18T01:06:55.979317Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_manual_time_features(df):\n",
    "    lags = [*np.arange(1,10), *np.arange(10,100,10), *np.arange(100,1000,100)]\n",
    "    def addTimeFeatures(i):\n",
    "        df['daskRate' + str(i)] = df.askRate0.diff(i)\n",
    "        df['dbidRate' + str(i)] = df.bidRate0.diff(i)\n",
    "    for i in lags:\n",
    "        addTimeFeatures(i)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T02:44:54.878665Z",
     "start_time": "2019-09-18T02:44:54.466653Z"
    }
   },
   "outputs": [],
   "source": [
    "massive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massive_df = add_manual_time_features(massive_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
