{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T08:53:59.674079Z",
     "start_time": "2019-09-26T08:53:59.668084Z"
    }
   },
   "outputs": [],
   "source": [
    "''' try using ta lib but change/adjust for different values of n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T08:54:00.141082Z",
     "start_time": "2019-09-26T08:54:00.135083Z"
    }
   },
   "outputs": [],
   "source": [
    "''' instead of appending, we shift(-1) and then update the last row in place'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:40.234203Z",
     "start_time": "2019-09-26T11:32:37.867605Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ta\n",
    "import lightgbm as lgb\n",
    "# from fastai import *\n",
    "# from fastai.tabular import *\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rolling import RollingWindowSplit\n",
    "from sklearn.metrics import r2_score as r2d2\n",
    "from joblib import dump, load\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "# %load_ext line_profiler\n",
    "sns.set(style = \"whitegrid\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.192619Z",
     "start_time": "2019-09-26T11:32:40.237492Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'D://Coding//XTX Forecasting Challenge//data-training.file'\n",
    "df = pd.read_feather(path, use_threads=8)\n",
    "df = df.astype('float32')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.204679Z",
     "start_time": "2019-09-26T11:32:48.195668Z"
    }
   },
   "outputs": [],
   "source": [
    "askRateList = ['askRate' + str(i) for i in range(0,15)]\n",
    "askSizeList = ['askSize' + str(i) for i in range(0,15)]\n",
    "bidRateList = ['bidRate' + str(i) for i in range(0,15)]\n",
    "bidSizeList = ['bidSize' + str(i) for i in range(0,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.215622Z",
     "start_time": "2019-09-26T11:32:48.208651Z"
    }
   },
   "outputs": [],
   "source": [
    "core = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.224621Z",
     "start_time": "2019-09-26T11:32:48.219620Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Figuring out what [y] is\n",
    "# # y(t) is midRate(t+87) - midRate(t), clipped to (-5.5)\n",
    "# df['expectedY'] = df.midRate.diff(87).shift(-87).clip(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.235621Z",
     "start_time": "2019-09-26T11:32:48.228618Z"
    }
   },
   "outputs": [],
   "source": [
    "# the public leaderboard set should have 150k observations: they check running time of 10k in 1h and max 15h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.697870Z",
     "start_time": "2019-09-26T11:32:48.239622Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70-30 train-valid and test split\n",
    "def train_valid_test_split(df):\n",
    "    valid_start = int(0.80*len(df))\n",
    "    test_start = int(0.95*len(df))\n",
    "    train_df = df[:valid_start].copy()\n",
    "    valid_df = df[valid_start:test_start].copy()\n",
    "    test_df = df[test_start:].copy()\n",
    "    return train_df, valid_df, test_df\n",
    "train_df, valid_df, test_df = train_valid_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.722605Z",
     "start_time": "2019-09-26T11:32:48.702536Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_limited_features_orig(df: pd.DataFrame, nums: list):\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    \n",
    "#     time features\n",
    "    for num in nums:\n",
    "        df['rsi' + str(num)] = ta.momentum.rsi(df.midRate, n=num)\n",
    "        df['tsi' + str(num)] = ta.momentum.tsi(df.midRate, s=num, r=2*num)\n",
    "        df['macd' + str(num)] = ta.trend.macd(df.midRate, n_fast=num, n_slow=int(num*2.5))\n",
    "        df['macd_diff' + str(num)] = ta.trend.macd_diff(df.midRate, n_fast=num, n_slow=int(num*2.5))\n",
    "        df['ema' + str(num)] = ta.trend.ema_indicator(df.midRate, n=num)\n",
    "        df['trix' + str(num)] = ta.trend.trix(df.midRate, n=num)\n",
    "        df['dpo' + str(num)] = ta.trend.dpo(df.midRate, n=num)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:32:48.731536Z",
     "start_time": "2019-09-26T11:32:48.726535Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcv = RollingWindowSplit(n_splits=3, compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:13.818265Z",
     "start_time": "2019-09-26T11:32:51.388846Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 15s min\n",
    "num=87\n",
    "limited_train = create_limited_features_orig(train_df, [*np.arange(num,num*10,num)])\n",
    "limited_valid = create_limited_features_orig(valid_df, [*np.arange(num,num*10,num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:13.827284Z",
     "start_time": "2019-09-26T11:34:13.821324Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(limited_df):\n",
    "    x_train = limited_df.replace([np.inf, -np.inf], np.nan).fillna(0).drop('y', axis=1).values\n",
    "    y_train = limited_df.y.values\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:27.925974Z",
     "start_time": "2019-09-26T11:34:13.832273Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 10s\n",
    "x_scaled_train, y_train = preprocess(limited_train)\n",
    "x_scaled_valid, y_valid = preprocess(limited_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:27.943979Z",
     "start_time": "2019-09-26T11:34:27.928977Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_params = {'boosting_type': 'gbdt',\n",
    "                'nthread': 4,\n",
    "                'random_state': 42,\n",
    "                'metric': 'rmse'}\n",
    "\n",
    "grid_params = {'learning_rate': [0.03, 0.04, 0.05, 0.1],\n",
    "                'num_leaves': [120,140,160,180,200,220,240,300,400,500],\n",
    "                'max_bin': [60,70,80,90,100],\n",
    "                'max_depth' : [0,1,2,3,4,5,6],\n",
    "                'colsample_bytree' : [0.7,0.8,0.9,1],\n",
    "                'subsample' : [0.3,0.5,0.7,0.9],\n",
    "                'min_split_gain' : [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99],\n",
    "                'min_data_in_leaf':[30,40,50,60,70,80,90,100],\n",
    "                'reg_alpha': [0.1,0.3,0.5,0.7,1],\n",
    "                'reg_lambda': [0.1,1,3,5],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:27.950981Z",
     "start_time": "2019-09-26T11:34:27.946978Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' RandomSearch for optimal LGBM parameters '''\n",
    "# clf = lgb.LGBMRegressor(**fixed_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2')\n",
    "# grid = RandomizedSearchCV(clf, grid_params, verbose=1, cv=rlcv, n_jobs = -1, n_iter=100)\n",
    "# grid.fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:34:27.963492Z",
     "start_time": "2019-09-26T11:34:27.953977Z"
    }
   },
   "outputs": [],
   "source": [
    "# true best params\n",
    "best_params = {'subsample': 0.7, 'reg_lambda': 1, 'reg_alpha': 0.5, 'num_leaves': 200, 'min_split_gain': 0.75,\n",
    "               'min_data_in_leaf': 50, 'max_depth': 3, 'max_bin': 70, 'learning_rate': 0.03, 'colsample_bytree': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:35:47.746911Z",
     "start_time": "2019-09-26T11:34:27.967575Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 1 min\n",
    "lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2').fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:35:50.531687Z",
     "start_time": "2019-09-26T11:35:47.752944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgbm.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lgbm, 'lgbm.joblib')\n",
    "# lgbm = load('lgbm110.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:35:50.549654Z",
     "start_time": "2019-09-26T11:35:50.534652Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(model, number_list, x_scaled_train, x_scaled_valid, y_train, y_valid):\n",
    "    train_score = model.score(x_scaled_train, y_train)\n",
    "    \n",
    "    predictions_valid = model.predict(x_scaled_valid)\n",
    "    valid_score = r2d2(y_valid, predictions_valid)\n",
    "    \n",
    "    limited_test = create_limited_features_orig(test_df, number_list)\n",
    "    x_scaled_test, y_test = preprocess(limited_test)\n",
    "    predictions_test = model.predict(x_scaled_test)\n",
    "    test_score = r2d2(y_test, predictions_test)\n",
    "    print(f'{train_score:.4f}, {valid_score:.4f}, {test_score:.4f}')\n",
    "    return predictions_test, limited_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:36:14.133459Z",
     "start_time": "2019-09-26T11:35:50.551649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0249, 0.0216, 0.0230\n"
     ]
    }
   ],
   "source": [
    "predictions_test, limited_test = score(lgbm, [*np.arange(num,num*10,num)], x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T11:01:24.775867Z",
     "start_time": "2019-09-26T11:01:03.909677Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "0.0249, 0.0216, 0.0230 for 10\n",
    "0.0252, 0.0218, 0.0201 for 15\n",
    "0.0257, 0.0218, 0.0205 for 20\n",
    "'''\n",
    "predictions_test, limited_test = score(lgbm, [*np.arange(num,num*10,num)], x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:51:56.897634Z",
     "start_time": "2019-09-26T09:51:46.763635Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test, limited_test = score(lgbm, [], x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:18:40.878075Z",
     "start_time": "2019-09-26T09:57:58.823796Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = [[*np.arange(num,num*10,num)] for num in range(51,151,10)]\n",
    "def test_various_windows(nums):\n",
    "    for number_list in tqdm_notebook(nums):\n",
    "        train = create_limited_features_orig(train_df, number_list)\n",
    "        valid = create_limited_features_orig(valid_df, number_list)\n",
    "        x_scaled_train, y_train = preprocess(train)\n",
    "        x_scaled_valid, y_valid = preprocess(valid)\n",
    "        lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid),\n",
    "                                 eval_metric='l2').fit(x_scaled_train, y_train)\n",
    "        print(f'Trying {number_list[0]} to {number_list[-1]}:', end='\\t')\n",
    "        predictions, limited_test = score(lgbm, number_list, x_scaled_train, x_scaled_valid,\n",
    "                                          y_train, y_valid)\n",
    "test_various_windows(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:36:35.997132Z",
     "start_time": "2019-09-25T08:35:57.452Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:49:02.053119Z",
     "start_time": "2019-09-26T10:49:01.634118Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "limit = 1000\n",
    "plt.plot(predictions_test[:limit])\n",
    "plt.plot(limited_test.y.values[:limit])\n",
    "plt.legend(['predictions', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:29:39.327822Z",
     "start_time": "2019-09-26T10:29:39.321816Z"
    }
   },
   "outputs": [],
   "source": [
    "a = lgbm.feature_importances_; a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:29:44.966966Z",
     "start_time": "2019-09-26T10:29:44.962946Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = limited_train.columns.drop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T04:23:07.626480Z",
     "start_time": "2019-09-26T04:23:07.621471Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''You should chuck the variables that meet this condition!'''\n",
    "columns.values[np.where(a<10,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:29:45.536498Z",
     "start_time": "2019-09-26T10:29:45.530481Z"
    }
   },
   "outputs": [],
   "source": [
    "'''These are the variables that contribute to the lgbm!'''\n",
    "columns.values[np.where(a>1,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:28:09.885712Z",
     "start_time": "2019-09-23T05:28:09.881710Z"
    }
   },
   "outputs": [],
   "source": [
    "dep_var = 'y'\n",
    "procs = [FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:28:10.530658Z",
     "start_time": "2019-09-23T05:28:10.525686Z"
    }
   },
   "outputs": [],
   "source": [
    "# fillmissing replaces with median // fill with zero could be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:31:38.299916Z",
     "start_time": "2019-09-23T05:31:38.295867Z"
    }
   },
   "outputs": [],
   "source": [
    "# use a subset of training data\n",
    "train_df = train_df[:int(5e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:07:35.879136Z",
     "start_time": "2019-09-23T06:07:28.030140Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 7s on 500k rows, 30s on full df\n",
    "test = TabularList.from_df(test_df, procs=procs)\n",
    "data = (TabularList.from_df(df = train_df, path='.', cont_names = df.columns.drop('y'), procs=procs)\n",
    "                            .split_by_idx(valid_idx=range(int(0.50*len(train_df)),int(len(train_df))))\n",
    "                            .label_from_df(cols=dep_var)\n",
    "                            .add_test(test, label=0)\n",
    "                            .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:04.868406Z",
     "start_time": "2019-09-23T06:08:04.670743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[500,200], metrics=[mean_absolute_error, r2_score], ps=[0.001,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:12:10.913422Z",
     "start_time": "2019-09-23T06:12:10.906421Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:32.167707Z",
     "start_time": "2019-09-23T06:08:09.641250Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find(end_lr=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:11:50.867107Z",
     "start_time": "2019-09-24T03:11:50.862109Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:34.023701Z",
     "start_time": "2019-09-23T06:08:32.171724Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model above has already diverged, we will restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch resnet model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:28.272978Z",
     "start_time": "2019-09-23T06:12:14.130064Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2m for 1 cycle\n",
    "learn.fit_one_cycle(1, 5e-4, wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:29.618035Z",
     "start_time": "2019-09-23T06:14:28.275975Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.416068Z",
     "start_time": "2019-09-23T06:14:30.394064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('new_fastai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.390062Z",
     "start_time": "2019-09-23T06:14:29.622015Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:15:00.783777Z",
     "start_time": "2019-09-23T06:14:30.419064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:48:28.754010Z",
     "start_time": "2019-09-23T05:48:28.695010Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:49:23.192015Z",
     "start_time": "2019-09-23T05:49:23.186013Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:100].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:53.245445Z",
     "start_time": "2019-09-23T06:20:52.962594Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[int(8.1e5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:54.105127Z",
     "start_time": "2019-09-23T06:20:54.098124Z"
    }
   },
   "outputs": [],
   "source": [
    "df.y.iloc[int(8.1e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:21:35.017074Z",
     "start_time": "2019-09-23T06:21:00.326024Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:22:24.129852Z",
     "start_time": "2019-09-23T06:22:24.099851Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.get_preds??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:40.939570Z",
     "start_time": "2019-09-26T09:53:40.934568Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_data_as_df(test_df, iteration, length):\n",
    "    return pd.DataFrame([test_df.head(length).iloc[iteration][:60].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:41.358600Z",
     "start_time": "2019-09-26T09:53:41.180600Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in a DataFrame row [df] of shape (1,60) and adds 10 cross-sectional features.\n",
    "Returns a DataFrame of shape (1,70).\n",
    "'''\n",
    "def create_limited_features(df):\n",
    "    df.columns = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:41.458599Z",
     "start_time": "2019-09-26T09:53:41.454597Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' Appends to [massive_df]=(many, >70) the DataFrame row [row]=(1,70). '''\n",
    "# def append_to_df(massive_df, row):\n",
    "#     try: row.index = [massive_df.index[-1] + timedelta(minutes=1)]\n",
    "#     except IndexError: row.index = [datetime(1970,1,1)]\n",
    "#     return massive_df.append(row, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:41.897101Z",
     "start_time": "2019-09-26T09:53:41.894108Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' Adds time-dependent features. All features that use shift/diff must come here. '''\n",
    "# def add_time_features(df, num):\n",
    "#     return df[-num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:42.963565Z",
     "start_time": "2019-09-26T09:53:42.956562Z"
    }
   },
   "outputs": [],
   "source": [
    "''' This function takes in all features and makes a bounded prediction. '''\n",
    "def get_prediction(data, model):\n",
    "    X = data.replace([np.inf, -np.inf], np.nan).values\n",
    "    return np.clip(model.predict(np.atleast_2d(X)), -5, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:53:45.541427Z",
     "start_time": "2019-09-26T09:53:45.532425Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' true_rlcvscore runs the submission functions on a test dataframe [test_df] taking the first [length] rows of [test_df].'''\n",
    "def true_rlcvscore(test_df, model, length):\n",
    "    predictions = []\n",
    "    log_data = pd.DataFrame()  # for debug\n",
    "    for iteration in tqdm_notebook(range(length)):\n",
    "        base_row = get_next_data_as_df(test_df, iteration, length)\n",
    "        row = create_limited_features(base_row)\n",
    "        data = pd.DataFrame(row)\n",
    "        log_data_row = data.copy() # for debug\n",
    "        prediction = get_prediction(data, model)\n",
    "        predictions.append(prediction)\n",
    "        log_data = log_data.append(log_data_row, sort=False) # for debug\n",
    "    true_values = test_df.y.head(length)\n",
    "    score = r2d2(true_values, predictions)\n",
    "    print(f'{score:.4f}')\n",
    "    return predictions, score, log_data, true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T09:54:33.429817Z",
     "start_time": "2019-09-26T09:53:46.735819Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 2m30s for 1000\n",
    "test_predictions, test_score, log_data, true_values = true_rlcvscore(test_df, lgbm, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:26:08.172974Z",
     "start_time": "2019-09-25T10:26:07.735972Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "plt.legend(['batch','line-by-line'], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The most important thing now is to reconcile the dataframes in submission and in batch prediction. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T03:35:12.757306Z",
     "start_time": "2019-09-26T03:35:11.933300Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot(test_predictions)\n",
    "plt.plot(true_values.values)\n",
    "plt.legend(['predictions', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T15:40:24.416970Z",
     "start_time": "2019-09-21T15:40:24.413968Z"
    }
   },
   "outputs": [],
   "source": [
    "# %lprun -f true_rlcvscore test_predictions, test_score = true_rlcvscore(test_df, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
