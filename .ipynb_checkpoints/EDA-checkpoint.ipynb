{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T08:53:59.674079Z",
     "start_time": "2019-09-26T08:53:59.668084Z"
    }
   },
   "outputs": [],
   "source": [
    "''' try predicting future values using lagged values (since we know t=87) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''should try to ensure that all the columns are aligned''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:09.942915Z",
     "start_time": "2019-09-26T16:45:07.532231Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ta\n",
    "import lightgbm as lgb\n",
    "# from fastai import *\n",
    "# from fastai.tabular import *\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rolling import RollingWindowSplit\n",
    "from sklearn.metrics import r2_score as r2d2\n",
    "from joblib import dump, load\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "# %load_ext line_profiler\n",
    "sns.set(style = \"whitegrid\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.414300Z",
     "start_time": "2019-09-26T16:45:09.945916Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'D://Coding//XTX Forecasting Challenge//data-training.file'\n",
    "df = pd.read_feather(path, use_threads=8)\n",
    "df = df.astype('float32')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.425310Z",
     "start_time": "2019-09-26T16:45:17.417299Z"
    }
   },
   "outputs": [],
   "source": [
    "askRateList = ['askRate' + str(i) for i in range(0,15)]\n",
    "askSizeList = ['askSize' + str(i) for i in range(0,15)]\n",
    "bidRateList = ['bidRate' + str(i) for i in range(0,15)]\n",
    "bidSizeList = ['bidSize' + str(i) for i in range(0,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.436297Z",
     "start_time": "2019-09-26T16:45:17.428300Z"
    }
   },
   "outputs": [],
   "source": [
    "core = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:02:09.304516Z",
     "start_time": "2019-09-26T16:02:09.299513Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Figuring out what [y] is\n",
    "# # y(t) is midRate(t+87) - midRate(t), clipped to (-5.5)\n",
    "# df['expectedY'] = df.midRate.diff(87).shift(-87).clip(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:02:09.312515Z",
     "start_time": "2019-09-26T16:02:09.309513Z"
    }
   },
   "outputs": [],
   "source": [
    "# the public leaderboard set should have 150k observations: they check running time of 10k in 1h and max 15h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.846294Z",
     "start_time": "2019-09-26T16:45:17.441298Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70-30 train-valid and test split\n",
    "def train_valid_test_split(df):\n",
    "    valid_start = int(0.80*len(df))\n",
    "    test_start = int(0.95*len(df))\n",
    "    train_df = df[:valid_start].copy()\n",
    "    valid_df = df[valid_start:test_start].copy()\n",
    "    test_df = df[test_start:].copy()\n",
    "    return train_df, valid_df, test_df\n",
    "train_df, valid_df, test_df = train_valid_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.866297Z",
     "start_time": "2019-09-26T16:45:17.848298Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_limited_features_orig(df: pd.DataFrame):\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    \n",
    "    # time features\n",
    "    rsi = [87, 348]\n",
    "    tsi = [174, 261, 348, 435, 522, 609, 696, 783]\n",
    "    macd = [87, 174, 348, 435, 522, 696, 783]\n",
    "    macd_diff = [87, 174, 261, 609, 696, 783]\n",
    "    ema = [435, 522, 783]\n",
    "    trix = [87, 174, 348, 435, 522, 609, 696, 783]\n",
    "    \n",
    "    for r in rsi:        df['rsi' + str(r)] = ta.momentum.rsi(df.midRate, n=r)\n",
    "    for t in tsi:        df['tsi' + str(t)] = ta.momentum.tsi(df.midRate, s=t, r=2*t)\n",
    "    for m in macd:       df['macd' + str(m)] = ta.trend.macd(df.midRate, n_fast=m, n_slow=int(m*2.5))\n",
    "    for m in macd_diff:  df['macd_diff' + str(m)] = ta.trend.macd_diff(df.midRate, n_fast=m, n_slow=int(m*2.5))\n",
    "    for e in ema:        df['ema' + str(e)] = ta.trend.ema_indicator(df.midRate, n=e)\n",
    "    for t in trix:       df['trix' + str(t)] = ta.trend.trix(df.midRate, n=t)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:45:17.875297Z",
     "start_time": "2019-09-26T16:45:17.869298Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcv = RollingWindowSplit(n_splits=3, compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:10.455296Z",
     "start_time": "2019-09-26T16:45:17.879297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 10 min\n",
    "limited_train = create_limited_features_orig(train_df)\n",
    "limited_valid = create_limited_features_orig(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:10.464301Z",
     "start_time": "2019-09-26T16:46:10.458298Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(limited_df):\n",
    "    x_train = limited_df.replace([np.inf, -np.inf], np.nan).fillna(0).drop('y', axis=1).values\n",
    "    y_train = limited_df.y.values\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:20.280298Z",
     "start_time": "2019-09-26T16:46:10.467301Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 10s\n",
    "x_scaled_train, y_train = preprocess(limited_train)\n",
    "x_scaled_valid, y_valid = preprocess(limited_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:20.293298Z",
     "start_time": "2019-09-26T16:46:20.283299Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_params = {'boosting_type': 'gbdt',\n",
    "                'nthread': 4,\n",
    "                'random_state': 42,\n",
    "                'metric': 'rmse'}\n",
    "\n",
    "grid_params = {'learning_rate': [0.03, 0.04, 0.05, 0.1],\n",
    "                'num_leaves': [120,140,160,180,200,220,240,300,400,500],\n",
    "                'max_bin': [60,70,80,90,100],\n",
    "                'max_depth' : [0,1,2,3,4,5,6],\n",
    "                'colsample_bytree' : [0.7,0.8,0.9,1],\n",
    "                'subsample' : [0.3,0.5,0.7,0.9],\n",
    "                'min_split_gain' : [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99],\n",
    "                'min_data_in_leaf':[30,40,50,60,70,80,90,100],\n",
    "                'reg_alpha': [0.1,0.3,0.5,0.7,1],\n",
    "                'reg_lambda': [0.1,1,3,5],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:20.301301Z",
     "start_time": "2019-09-26T16:46:20.296299Z"
    }
   },
   "outputs": [],
   "source": [
    "# ''' RandomSearch for optimal LGBM parameters '''\n",
    "# clf = lgb.LGBMRegressor(**fixed_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2')\n",
    "# grid = RandomizedSearchCV(clf, grid_params, verbose=1, cv=rlcv, n_jobs = -1, n_iter=100)\n",
    "# grid.fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:20.315301Z",
     "start_time": "2019-09-26T16:46:20.308300Z"
    }
   },
   "outputs": [],
   "source": [
    "# true best params\n",
    "best_params = {'subsample': 0.7, 'reg_lambda': 1, 'reg_alpha': 0.5, 'num_leaves': 160, 'min_split_gain': 0.75,\n",
    "               'min_data_in_leaf': 50, 'max_depth': 3, 'max_bin': 70, 'learning_rate': 0.03, 'colsample_bytree': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:38:53.539162Z",
     "start_time": "2019-09-26T16:38:00.383164Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 1 min\n",
    "lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2').fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:46:20.345296Z",
     "start_time": "2019-09-26T16:46:20.318299Z"
    }
   },
   "outputs": [],
   "source": [
    "# lgbm.booster_.save_model('booster.txt')\n",
    "bst = lgb.Booster(model_file='booster.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:27:31.108268Z",
     "start_time": "2019-09-26T16:27:28.176004Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump(lgbm, 'lgbm.joblib')\n",
    "# lgbm = load('lgbm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:47:24.782955Z",
     "start_time": "2019-09-26T16:47:24.777937Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(model, x_scaled_train, x_scaled_valid, y_train, y_valid):\n",
    "    predictions_train = model.predict(x_scaled_train)\n",
    "    train_score = r2d2(y_train, predictions_train)\n",
    "#     train_score = model.score(x_scaled_train, y_train)\n",
    "    \n",
    "    predictions_valid = model.predict(x_scaled_valid)\n",
    "    valid_score = r2d2(y_valid, predictions_valid)\n",
    "    \n",
    "    limited_test = create_limited_features_orig(test_df)\n",
    "    x_scaled_test, y_test = preprocess(limited_test)\n",
    "    predictions_test = model.predict(x_scaled_test)\n",
    "    test_score = r2d2(y_test, predictions_test)\n",
    "    print(f'{train_score:.4f}, {valid_score:.4f}, {test_score:.4f}')\n",
    "    return predictions_test, limited_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 0.0251, 0.0217, 0.0226 expected'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:47:43.875883Z",
     "start_time": "2019-09-26T16:47:27.635881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0251, 0.0217, 0.0226\n"
     ]
    }
   ],
   "source": [
    "predictions_test, limited_test = score(bst, x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:18:59.795912Z",
     "start_time": "2019-09-26T16:18:44.708912Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test, limited_test = score(lgbm, x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T13:29:45.351489Z",
     "start_time": "2019-09-26T13:29:45.313503Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "0.0250, 0.0217, 0.0216 with everything\n",
    "0.0249, 0.0216, 0.0230 for 88 with dpo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T14:40:50.086847Z",
     "start_time": "2019-09-26T14:31:56.655269Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = [*np.linspace(2.4,2.8,7)]\n",
    "def test_various_windows(nums):\n",
    "    for num in tqdm_notebook(nums):\n",
    "        train = create_limited_features_orig(train_df, num)\n",
    "        valid = create_limited_features_orig(valid_df, num)\n",
    "        x_scaled_train, y_train = preprocess(train)\n",
    "        x_scaled_valid, y_valid = preprocess(valid)\n",
    "        lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid),\n",
    "                                 eval_metric='l2').fit(x_scaled_train, y_train)\n",
    "        print(f'Trying {num}:', end='\\t')\n",
    "        predictions, limited_test = score(lgbm, num, x_scaled_train, x_scaled_valid, y_train, y_valid)\n",
    "test_various_windows(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:36:35.997132Z",
     "start_time": "2019-09-25T08:35:57.452Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T10:49:02.053119Z",
     "start_time": "2019-09-26T10:49:01.634118Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "limit = 1000\n",
    "plt.plot(predictions_test[:limit])\n",
    "plt.plot(limited_test.y.values[:limit])\n",
    "plt.legend(['predictions', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:35:15.573798Z",
     "start_time": "2019-09-26T15:35:15.566801Z"
    }
   },
   "outputs": [],
   "source": [
    "a = lgbm.feature_importances_; a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:36:43.748228Z",
     "start_time": "2019-09-26T15:36:43.742226Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = limited_train.columns.drop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:37:47.169725Z",
     "start_time": "2019-09-26T15:37:47.161687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''You should chuck the variables that meet this condition!'''\n",
    "columns.values[np.where(a==0,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:39:37.926159Z",
     "start_time": "2019-09-26T15:39:37.918160Z"
    }
   },
   "outputs": [],
   "source": [
    "'''These are the variables that contribute to the lgbm!'''\n",
    "columns.values[np.where(a>0,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:28:09.885712Z",
     "start_time": "2019-09-23T05:28:09.881710Z"
    }
   },
   "outputs": [],
   "source": [
    "dep_var = 'y'\n",
    "procs = [FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:31:38.299916Z",
     "start_time": "2019-09-23T05:31:38.295867Z"
    }
   },
   "outputs": [],
   "source": [
    "# use a subset of training data\n",
    "train_df = train_df[:int(5e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:07:35.879136Z",
     "start_time": "2019-09-23T06:07:28.030140Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 7s on 500k rows, 30s on full df\n",
    "test = TabularList.from_df(test_df, procs=procs)\n",
    "data = (TabularList.from_df(df = train_df, path='.', cont_names = df.columns.drop('y'), procs=procs)\n",
    "                            .split_by_idx(valid_idx=range(int(0.50*len(train_df)),int(len(train_df))))\n",
    "                            .label_from_df(cols=dep_var)\n",
    "                            .add_test(test, label=0)\n",
    "                            .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:04.868406Z",
     "start_time": "2019-09-23T06:08:04.670743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[500,200], metrics=[mean_absolute_error, r2_score], ps=[0.001,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:12:10.913422Z",
     "start_time": "2019-09-23T06:12:10.906421Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:32.167707Z",
     "start_time": "2019-09-23T06:08:09.641250Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find(end_lr=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:11:50.867107Z",
     "start_time": "2019-09-24T03:11:50.862109Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:34.023701Z",
     "start_time": "2019-09-23T06:08:32.171724Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model above has already diverged, we will restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch resnet model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:28.272978Z",
     "start_time": "2019-09-23T06:12:14.130064Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2m for 1 cycle\n",
    "learn.fit_one_cycle(1, 5e-4, wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:29.618035Z",
     "start_time": "2019-09-23T06:14:28.275975Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.416068Z",
     "start_time": "2019-09-23T06:14:30.394064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('new_fastai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.390062Z",
     "start_time": "2019-09-23T06:14:29.622015Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:15:00.783777Z",
     "start_time": "2019-09-23T06:14:30.419064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:48:28.754010Z",
     "start_time": "2019-09-23T05:48:28.695010Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:49:23.192015Z",
     "start_time": "2019-09-23T05:49:23.186013Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:100].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:53.245445Z",
     "start_time": "2019-09-23T06:20:52.962594Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[int(8.1e5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:54.105127Z",
     "start_time": "2019-09-23T06:20:54.098124Z"
    }
   },
   "outputs": [],
   "source": [
    "df.y.iloc[int(8.1e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:21:35.017074Z",
     "start_time": "2019-09-23T06:21:00.326024Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:22:24.129852Z",
     "start_time": "2019-09-23T06:22:24.099851Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.get_preds??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:13:17.647742Z",
     "start_time": "2019-09-26T16:13:17.634741Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_data_as_df(test_df, iteration, length):\n",
    "    return pd.DataFrame([test_df.head(length).iloc[iteration][:60].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:13:18.825603Z",
     "start_time": "2019-09-26T16:13:18.106603Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in a DataFrame row [df] of shape (1,60) and adds 10 cross-sectional features.\n",
    "Returns a DataFrame of shape (1,70).\n",
    "'''\n",
    "def create_limited_features(df):\n",
    "    df.columns = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:13:18.837600Z",
     "start_time": "2019-09-26T16:13:18.828603Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Appends to [massive_df]=(many, >70) the DataFrame row [row]=(1,70). '''\n",
    "''' When length limit is reached, instead of appending (memory intensive), we shift(-1) and then update the last row in place. '''\n",
    "def append_to_df(massive_df, row):\n",
    "    return massive_df.append(row, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:14:08.602107Z",
     "start_time": "2019-09-26T16:14:08.590097Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Adds time-dependent features. All features that use shift/diff must come here. '''\n",
    "def add_time_features(df, massive_df_length):\n",
    "    rsi = [87, 348]\n",
    "    tsi = [174, 261, 348, 435, 522, 609, 696, 783]\n",
    "    macd = [87, 174, 348, 435, 522, 696, 783]\n",
    "    macd_diff = [87, 174, 261, 609, 696, 783]\n",
    "    ema = [435, 522, 783]\n",
    "    trix = [87, 174, 348, 435, 522, 609, 696, 783]\n",
    "    \n",
    "    for r in rsi:        df['rsi' + str(r)] = ta.momentum.rsi(df.midRate, n=r)\n",
    "    for t in tsi:        df['tsi' + str(t)] = ta.momentum.tsi(df.midRate, s=t, r=2*t)\n",
    "    for m in macd:       df['macd' + str(m)] = ta.trend.macd(df.midRate, n_fast=m, n_slow=int(m*2.5))\n",
    "    for m in macd_diff:  df['macd_diff' + str(m)] = ta.trend.macd_diff(df.midRate, n_fast=m, n_slow=int(m*2.5))\n",
    "    for e in ema:        df['ema' + str(e)] = ta.trend.ema_indicator(df.midRate, n=e)\n",
    "    for t in trix:       df['trix' + str(t)] = ta.trend.trix(df.midRate, n=t)\n",
    "    return df[-massive_df_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:41:03.190274Z",
     "start_time": "2019-09-26T16:41:03.184272Z"
    }
   },
   "outputs": [],
   "source": [
    "''' This function takes in all features and makes a bounded prediction. '''\n",
    "def get_prediction(data, model):\n",
    "    X = data.replace([np.inf, -np.inf], np.nan).values\n",
    "    return np.clip(bst.predict(np.atleast_2d(X)), -5, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:13:20.332242Z",
     "start_time": "2019-09-26T16:13:20.320240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' true_rlcvscore runs the submission functions on a test dataframe [test_df] taking the first [length] rows of [test_df].'''\n",
    "def true_rlcvscore(test_df, model, length):\n",
    "    massive_df_length = 875\n",
    "    massive_df, predictions = pd.DataFrame(), []\n",
    "    log_data = pd.DataFrame()  # for debug\n",
    "    for iteration in tqdm_notebook(range(length)):\n",
    "        base_row = get_next_data_as_df(test_df, iteration, length)\n",
    "        row = create_limited_features(base_row)\n",
    "        massive_df = append_to_df(massive_df, row)\n",
    "        massive_df = add_time_features(massive_df, massive_df_length)\n",
    "        data = pd.DataFrame([massive_df.iloc[-1]])\n",
    "        log_data_row = data.copy() # for debug\n",
    "        prediction = get_prediction(data, model)\n",
    "        predictions.append(prediction)\n",
    "        log_data = log_data.append(log_data_row, sort=False) # for debug\n",
    "    true_values = test_df.y.head(length)\n",
    "    score = r2d2(true_values, predictions)\n",
    "    print(f'{score:.4f}')\n",
    "    return predictions, score, log_data, true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T16:44:41.510308Z",
     "start_time": "2019-09-26T16:41:06.076306Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 2m30s for 1000\n",
    "# massive_d = true_rlcvscore(test_df, lgbm, 1000)\n",
    "test_predictions, test_score, log_data, true_values = true_rlcvscore(test_df, lgbm, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:28:15.174379Z",
     "start_time": "2019-09-26T15:28:14.952382Z"
    }
   },
   "outputs": [],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T15:29:29.190708Z",
     "start_time": "2019-09-26T15:29:28.663709Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot(test_predictions)\n",
    "plt.plot(true_values.values)\n",
    "plt.legend(['predictions', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T15:40:24.416970Z",
     "start_time": "2019-09-21T15:40:24.413968Z"
    }
   },
   "outputs": [],
   "source": [
    "# %lprun -f true_rlcvscore test_predictions, test_score = true_rlcvscore(test_df, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
