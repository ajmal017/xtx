{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:52.552307Z",
     "start_time": "2019-09-25T10:39:50.456303Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ta\n",
    "import lightgbm as lgb\n",
    "# from fastai import *\n",
    "# from fastai.tabular import *\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from rolling import RollingWindowSplit\n",
    "from sklearn.metrics import r2_score as r2d2\n",
    "from joblib import dump, load\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "sns.set(style = \"whitegrid\")\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:52.559305Z",
     "start_time": "2019-09-25T10:39:52.555303Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# path = 'D://Coding//XTX Forecasting Challenge//data-training.csv'\n",
    "# df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.613142Z",
     "start_time": "2019-09-25T10:39:52.562307Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'D://Coding//XTX Forecasting Challenge//data-training.file'\n",
    "df = pd.read_feather(path, use_threads=8)\n",
    "df = df.astype('float32')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.622143Z",
     "start_time": "2019-09-25T10:39:58.616141Z"
    }
   },
   "outputs": [],
   "source": [
    "askRateList = ['askRate' + str(i) for i in range(0,15)]\n",
    "askSizeList = ['askSize' + str(i) for i in range(0,15)]\n",
    "bidRateList = ['bidRate' + str(i) for i in range(0,15)]\n",
    "bidSizeList = ['bidSize' + str(i) for i in range(0,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.636142Z",
     "start_time": "2019-09-25T10:39:58.625141Z"
    }
   },
   "outputs": [],
   "source": [
    "core = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.648143Z",
     "start_time": "2019-09-25T10:39:58.641146Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['others_dr', 'others_dlr', 'others_cr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.655141Z",
     "start_time": "2019-09-25T10:39:58.651147Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Figuring out what [y] is\n",
    "# # y(t) is midRate(t+87) - midRate(t), clipped to (-5.5)\n",
    "# df['expectedY'] = df.midRate.diff(87).shift(-87).clip(-5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:58.663141Z",
     "start_time": "2019-09-25T10:39:58.658143Z"
    }
   },
   "outputs": [],
   "source": [
    "# the public leaderboard set should have 150k observations: they check running time of 10k in 1h and max 15h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:59.116142Z",
     "start_time": "2019-09-25T10:39:58.666143Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70-30 train-valid and test split\n",
    "def train_valid_test_split(df):\n",
    "    valid_start = int(0.80*len(df))\n",
    "    test_start = int(0.95*len(df))\n",
    "    train_df = df[:valid_start].copy()\n",
    "    valid_df = df[valid_start:test_start].copy()\n",
    "    test_df = df[test_start:].copy()\n",
    "    return train_df, valid_df, test_df\n",
    "train_df, valid_df, test_df = train_valid_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:59.136143Z",
     "start_time": "2019-09-25T10:39:59.118142Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_limited_features_orig(df, num):\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    \n",
    "    # resample features\n",
    "    df['time'] = pd.date_range(start='1/1/1970', periods=len(df), freq='T')\n",
    "    df.set_index('time', inplace=True)\n",
    "    df_mid = df.midRate.resample(str(num)+'Min').ohlc()\n",
    "    df_mid['vol'] = df.bidAskVol.resample(str(num)+'Min').mean()\n",
    "    def create_ohlc_features(df_mid, open_, high_, low_, close_, vol_):\n",
    "        df_mid = ta.add_others_ta(df_mid, close_)\n",
    "        return df_mid\n",
    "    df_mid = create_ohlc_features(df_mid, 'open', 'high', 'low', 'close', 'vol')\n",
    "    df = df.join(df_mid[df_mid.columns.drop(['open', 'high', 'low', 'close', 'vol'])]).ffill().astype('float32')\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df, df_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:39:59.207141Z",
     "start_time": "2019-09-25T10:39:59.203142Z"
    }
   },
   "outputs": [],
   "source": [
    "rlcv = RollingWindowSplit(n_splits=3, compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:10.328445Z",
     "start_time": "2019-09-25T10:39:59.720448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 15s min\n",
    "limited_train, df_mid_train = create_limited_features_orig(train_df, 120)\n",
    "limited_valid, df_mid_valid = create_limited_features_orig(valid_df, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:10.339451Z",
     "start_time": "2019-09-25T10:40:10.330449Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardise(limited_train, scaler):\n",
    "    x_train = limited_train.replace([np.inf, -np.inf], np.nan).fillna(0).drop('y', axis=1).values\n",
    "    y_train = limited_train.y.values\n",
    "    if scaler=='train':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "    x_scaled_train = scaler.transform(x_train)\n",
    "    return x_scaled_train, y_train, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:19.065447Z",
     "start_time": "2019-09-25T10:40:10.342451Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 10s\n",
    "x_scaled_train, y_train, scaler = standardise(limited_train, scaler='train')\n",
    "x_scaled_valid, y_valid, scaler = standardise(limited_valid, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:19.078453Z",
     "start_time": "2019-09-25T10:40:19.067449Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_params = {'boosting_type': 'gbdt',\n",
    "                'nthread': 4,\n",
    "                'random_state': 42,\n",
    "                'metric': 'rmse'}\n",
    "\n",
    "grid_params = {'learning_rate': [0.02, 0.03, 0.04, 0.05],\n",
    "                'num_leaves': [120,140,160,180,200],\n",
    "                'max_bin': [60,70,80,90,100],\n",
    "                'max_depth' : [0,1,2,3,4,5],\n",
    "                'colsample_bytree' : [0.7,0.8,0.9,1],\n",
    "                'subsample' : [0.3,0.5,0.7],\n",
    "                'min_split_gain' : [0.6, 0.7, 0.8, 0.9],\n",
    "                'min_data_in_leaf':[30,40,50,60],\n",
    "                'reg_alpha': [0.1,0.3,0.5,0.7,1],\n",
    "                'reg_lambda': [0.1,1,5,10],\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:19.094448Z",
     "start_time": "2019-09-25T10:40:19.081451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' RandomSearch for optimal LGBM parameters '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' RandomSearch for optimal LGBM parameters '''\n",
    "# clf = lgb.LGBMRegressor(**fixed_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2')\n",
    "# grid3 = RandomizedSearchCV(clf, grid_params, verbose=1, cv=rlcv, n_jobs = -1, n_iter=30)\n",
    "# grid3.fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:19.103452Z",
     "start_time": "2019-09-25T10:40:19.098450Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = {'subsample': 0.7, 'reg_lambda': 0.1, 'reg_alpha': 0.3,\n",
    "                'num_leaves': 200, 'min_split_gain': 0.9, 'min_data_in_leaf': 60,\n",
    "                'max_depth': 3, 'max_bin': 60, 'learning_rate': 0.02, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.382467Z",
     "start_time": "2019-09-25T10:40:19.107457Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 41s min\n",
    "lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid), eval_metric='l2').fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:06.559453Z",
     "start_time": "2019-09-25T10:41:06.152450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgbm120.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(scaler, 'scaler120.joblib')\n",
    "dump(lgbm, 'lgbm120.joblib')\n",
    "# scaler = load('scaler110.joblib')\n",
    "# lgbm = load('lgbm110.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.402450Z",
     "start_time": "2019-09-25T10:40:55.394449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' We want to try different ohlc window sizes. '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' We want to try different ohlc window sizes. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.414452Z",
     "start_time": "2019-09-25T10:40:55.405449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrying 2:\\t0.0188, 0.0205, 0.0190\\nTrying 5:\\t0.0233, 0.0254, 0.0245\\nTrying 8:\\t0.0294, 0.0321, 0.0317\\nTrying 11:\\t0.0363, 0.0395, 0.0380\\nTrying 14:\\t0.0440, 0.0461, 0.0464\\nTrying 17:\\t0.0514, 0.0535, 0.0508\\nTrying 20:\\t0.0585, 0.0606, 0.0614\\nTrying 23:\\t0.0665, 0.0695, 0.0659\\nTrying 26:\\t0.0746, 0.0773, 0.0745\\nTrying 29:\\t0.0833, 0.0861, 0.0826\\nTrying 32:\\t0.0916, 0.0900, 0.0902\\nTrying 35:\\t0.0989, 0.1000, 0.0979\\nTrying 38:\\t0.1075, 0.1050, 0.1090\\nTrying 41:\\t0.1134, 0.1107, 0.1231\\nTrying 44:\\t0.1208, 0.1220, 0.1297\\nTrying 47:\\t0.1317, 0.1267, 0.1346\\nTrying 50:\\t0.1372, 0.1378, 0.1370\\nTrying 53:\\t0.1478, 0.1440, 0.1552\\nTrying 56:\\t0.1529, 0.1496, 0.1559\\nTrying 59:\\t0.1602, 0.1608, 0.1679\\nTrying 62:\\t0.1672, 0.1639, 0.1766\\nTrying 65:\\t0.1800, 0.1795, 0.1828\\nTrying 68:\\t0.1820, 0.1820, 0.1692\\nTrying 71:\\t0.1937, 0.2007, 0.1959\\nTrying 74:\\t0.2032, 0.2005, 0.2216\\nTrying 77:\\t0.2076, 0.2088, 0.2094\\nTrying 80:\\t0.2149, 0.2129, 0.2235\\nTrying 83:\\t0.2271, 0.2210, 0.2297\\nTrying 86:\\t0.2338, 0.2277, 0.2343\\nTrying 89:\\t0.2403, 0.2400, 0.2647\\nTrying 92:\\t0.2510, 0.2408, 0.2570 <-- maybe consider 90 as well\\nTrying 95:\\t0.2594, 0.2500, 0.2708\\nTrying 98:\\t0.2649, 0.2538, 0.2646\\nTrying 101:\\t0.2631, 0.2634, 0.2577\\nTrying 104:\\t0.2727, 0.2718, 0.2954\\nTrying 107:\\t0.2699, 0.2803, 0.2831\\nTrying 110:\\t0.2775, 0.2743, 0.3013 <-- memory constraints suggest we use 110 (actually..idk)\\nTrying 113:\\t0.2778, 0.2718, 0.2952\\nTrying 116:\\t0.2799, 0.2760, 0.2854\\nTrying 119:\\t0.2781, 0.2704, 0.2955 <-- we use 120 to avoid a misalignment problem in time\\nTrying 122:\\t0.2799, 0.2777, 0.2891\\nTrying 125:\\t0.2843, 0.2844, 0.2864\\nTrying 128:\\t0.2890, 0.2738, 0.3027\\nTrying 131:\\t0.2874, 0.2843, 0.2938\\nTrying 134:\\t0.2833, 0.2774, 0.2956\\nTrying 137:\\t0.2858, 0.2844, 0.2822\\nTrying 140:\\t0.2828, 0.2754, 0.2930\\nTrying 143:\\t0.2815, 0.2752, 0.3085\\nTrying 146:\\t0.2751, 0.2774, 0.3054\\nTrying 149:\\t0.2824, 0.2827, 0.2950\\n\\nTrying 155:\\t0.2763, 0.2797, 0.2963\\nTrying 160:\\t0.2799, 0.2643, 0.2847\\nTrying 165:\\t0.2705, 0.2753, 0.2890\\nTrying 170:\\t0.2752, 0.2643, 0.2683\\nTrying 175:\\t0.2759, 0.2630, 0.2779\\nTrying 180:\\t0.2670, 0.2544, 0.2736\\nTrying 185:\\t0.2639, 0.2499, 0.2638\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trying 2:\t0.0188, 0.0205, 0.0190\n",
    "Trying 5:\t0.0233, 0.0254, 0.0245\n",
    "Trying 8:\t0.0294, 0.0321, 0.0317\n",
    "Trying 11:\t0.0363, 0.0395, 0.0380\n",
    "Trying 14:\t0.0440, 0.0461, 0.0464\n",
    "Trying 17:\t0.0514, 0.0535, 0.0508\n",
    "Trying 20:\t0.0585, 0.0606, 0.0614\n",
    "Trying 23:\t0.0665, 0.0695, 0.0659\n",
    "Trying 26:\t0.0746, 0.0773, 0.0745\n",
    "Trying 29:\t0.0833, 0.0861, 0.0826\n",
    "Trying 32:\t0.0916, 0.0900, 0.0902\n",
    "Trying 35:\t0.0989, 0.1000, 0.0979\n",
    "Trying 38:\t0.1075, 0.1050, 0.1090\n",
    "Trying 41:\t0.1134, 0.1107, 0.1231\n",
    "Trying 44:\t0.1208, 0.1220, 0.1297\n",
    "Trying 47:\t0.1317, 0.1267, 0.1346\n",
    "Trying 50:\t0.1372, 0.1378, 0.1370\n",
    "Trying 53:\t0.1478, 0.1440, 0.1552\n",
    "Trying 56:\t0.1529, 0.1496, 0.1559\n",
    "Trying 59:\t0.1602, 0.1608, 0.1679\n",
    "Trying 62:\t0.1672, 0.1639, 0.1766\n",
    "Trying 65:\t0.1800, 0.1795, 0.1828\n",
    "Trying 68:\t0.1820, 0.1820, 0.1692\n",
    "Trying 71:\t0.1937, 0.2007, 0.1959\n",
    "Trying 74:\t0.2032, 0.2005, 0.2216\n",
    "Trying 77:\t0.2076, 0.2088, 0.2094\n",
    "Trying 80:\t0.2149, 0.2129, 0.2235\n",
    "Trying 83:\t0.2271, 0.2210, 0.2297\n",
    "Trying 86:\t0.2338, 0.2277, 0.2343\n",
    "Trying 89:\t0.2403, 0.2400, 0.2647\n",
    "Trying 92:\t0.2510, 0.2408, 0.2570 <-- maybe consider 90 as well\n",
    "Trying 95:\t0.2594, 0.2500, 0.2708\n",
    "Trying 98:\t0.2649, 0.2538, 0.2646\n",
    "Trying 101:\t0.2631, 0.2634, 0.2577\n",
    "Trying 104:\t0.2727, 0.2718, 0.2954\n",
    "Trying 107:\t0.2699, 0.2803, 0.2831\n",
    "Trying 110:\t0.2775, 0.2743, 0.3013 <-- memory constraints suggest we use 110 (actually..idk)\n",
    "Trying 113:\t0.2778, 0.2718, 0.2952\n",
    "Trying 116:\t0.2799, 0.2760, 0.2854\n",
    "Trying 119:\t0.2781, 0.2704, 0.2955 <-- we use 120 to avoid a misalignment problem in time\n",
    "Trying 122:\t0.2799, 0.2777, 0.2891\n",
    "Trying 125:\t0.2843, 0.2844, 0.2864\n",
    "Trying 128:\t0.2890, 0.2738, 0.3027\n",
    "Trying 131:\t0.2874, 0.2843, 0.2938\n",
    "Trying 134:\t0.2833, 0.2774, 0.2956\n",
    "Trying 137:\t0.2858, 0.2844, 0.2822\n",
    "Trying 140:\t0.2828, 0.2754, 0.2930\n",
    "Trying 143:\t0.2815, 0.2752, 0.3085\n",
    "Trying 146:\t0.2751, 0.2774, 0.3054\n",
    "Trying 149:\t0.2824, 0.2827, 0.2950\n",
    "\n",
    "Trying 155:\t0.2763, 0.2797, 0.2963\n",
    "Trying 160:\t0.2799, 0.2643, 0.2847\n",
    "Trying 165:\t0.2705, 0.2753, 0.2890\n",
    "Trying 170:\t0.2752, 0.2643, 0.2683\n",
    "Trying 175:\t0.2759, 0.2630, 0.2779\n",
    "Trying 180:\t0.2670, 0.2544, 0.2736\n",
    "Trying 185:\t0.2639, 0.2499, 0.2638\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.425449Z",
     "start_time": "2019-09-25T10:40:55.417449Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(model, scaler, number, x_scaled_train, x_scaled_valid, y_train, y_valid):\n",
    "    train_score = model.score(x_scaled_train, y_train)\n",
    "    predictions_valid = model.predict(x_scaled_valid)\n",
    "    valid_score = r2d2(y_valid, predictions_valid)\n",
    "    limited_test, df_mid_test = create_limited_features_orig(test_df, number)\n",
    "    x_scaled_test, y_test, scaler = standardise(limited_test, scaler=scaler)\n",
    "    predictions_test = model.predict(x_scaled_test)\n",
    "    test_score = r2d2(y_test, predictions_test)\n",
    "    print(f'{train_score:.4f}, {valid_score:.4f}, {test_score:.4f}')\n",
    "    return predictions_test, limited_test, df_mid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.433450Z",
     "start_time": "2019-09-25T10:40:55.427448Z"
    }
   },
   "outputs": [],
   "source": [
    "# nums = list(np.arange(255,500,10))\n",
    "# def test_various_windows():\n",
    "#     for number in tqdm_notebook(nums):\n",
    "#         train = create_limited_features_orig(train_df, number)\n",
    "#         valid = create_limited_features_orig(valid_df, number)\n",
    "#         x_scaled_train, y_train, scaler = standardise(train, scaler='train')\n",
    "#         x_scaled_valid, y_valid, scaler = standardise(valid, scaler=scaler)\n",
    "#         lgbm = lgb.LGBMRegressor(**fixed_params, **best_params, eval_set=(x_scaled_valid, y_valid),\n",
    "#                                  eval_metric='l2').fit(x_scaled_train, y_train)\n",
    "#         print(f'Trying {number}:', end='\\t')\n",
    "#         predictions, limited_test = score(lgbm, scaler, number, x_scaled_train, x_scaled_valid,\n",
    "#                                           y_train, y_valid)\n",
    "# test_various_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.443454Z",
     "start_time": "2019-09-25T10:40:55.436452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -1000 has scores of (0.0457, 0.0481, -0.1535) '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' -1000 has scores of (0.0457, 0.0481, -0.1535) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:40:55.456451Z",
     "start_time": "2019-09-25T10:40:55.449454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train on entire dataset!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Shifted features are super important!'''\n",
    "'''Don't drop original variables!'''\n",
    "'''Train on entire dataset!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:06.149453Z",
     "start_time": "2019-09-25T10:40:55.459452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2736, 0.2683, 0.3011\n"
     ]
    }
   ],
   "source": [
    "predictions, limited_test, df_mid_test = score(lgbm, scaler, 120, x_scaled_train, x_scaled_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:36:35.997132Z",
     "start_time": "2019-09-25T08:35:57.452Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:36:35.999120Z",
     "start_time": "2019-09-25T08:35:58.505Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot(predictions[:10000])\n",
    "plt.plot(limited_test.y.values[:10000])\n",
    "plt.legend(['predictions','true y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T08:55:14.420678Z",
     "start_time": "2019-09-24T08:54:58.303670Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 1 min\n",
    "predictions, limited_test = score(lgbm, scaler) # 0.95 most recent\n",
    "''' 0.95 has scores of (0.0456, 0.0489, 0.0451)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:32:23.230764Z",
     "start_time": "2019-09-25T08:32:23.223761Z"
    }
   },
   "outputs": [],
   "source": [
    "a = lgbm.feature_importances_; a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:33:45.066328Z",
     "start_time": "2019-09-25T08:33:45.060350Z"
    }
   },
   "outputs": [],
   "source": [
    "limited_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:32:55.397594Z",
     "start_time": "2019-09-25T08:32:55.390591Z"
    }
   },
   "outputs": [],
   "source": [
    "np.where(a<10,1,0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:33:13.602668Z",
     "start_time": "2019-09-25T08:33:13.597658Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = limited_train.columns.drop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:33:17.012635Z",
     "start_time": "2019-09-25T08:33:17.003666Z"
    }
   },
   "outputs": [],
   "source": [
    "'''You should chuck the variables that meet this condition!'''\n",
    "cols.values[np.where(a<10,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:34:05.644790Z",
     "start_time": "2019-09-25T08:34:05.637777Z"
    }
   },
   "outputs": [],
   "source": [
    "cols.values[np.where(a>100,1,0).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T01:47:47.406704Z",
     "start_time": "2019-09-23T01:47:45.499708Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, limited_test, df_mid_test = score(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:28:09.885712Z",
     "start_time": "2019-09-23T05:28:09.881710Z"
    }
   },
   "outputs": [],
   "source": [
    "dep_var = 'y'\n",
    "procs = [FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:28:10.530658Z",
     "start_time": "2019-09-23T05:28:10.525686Z"
    }
   },
   "outputs": [],
   "source": [
    "# fillmissing replaces with median // fill with zero could be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:31:38.299916Z",
     "start_time": "2019-09-23T05:31:38.295867Z"
    }
   },
   "outputs": [],
   "source": [
    "# use a subset of training data\n",
    "train_df = train_df[:int(5e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:07:35.879136Z",
     "start_time": "2019-09-23T06:07:28.030140Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 7s on 500k rows, 30s on full df\n",
    "test = TabularList.from_df(test_df, procs=procs)\n",
    "data = (TabularList.from_df(df = train_df, path='.', cont_names = df.columns.drop('y'), procs=procs)\n",
    "                            .split_by_idx(valid_idx=range(int(0.50*len(train_df)),int(len(train_df))))\n",
    "                            .label_from_df(cols=dep_var)\n",
    "                            .add_test(test, label=0)\n",
    "                            .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:04.868406Z",
     "start_time": "2019-09-23T06:08:04.670743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[500,200], metrics=[mean_absolute_error, r2_score], ps=[0.001,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:12:10.913422Z",
     "start_time": "2019-09-23T06:12:10.906421Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:32.167707Z",
     "start_time": "2019-09-23T06:08:09.641250Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find(end_lr=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T03:11:50.867107Z",
     "start_time": "2019-09-24T03:11:50.862109Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:08:34.023701Z",
     "start_time": "2019-09-23T06:08:32.171724Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model above has already diverged, we will restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pytorch resnet model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:28.272978Z",
     "start_time": "2019-09-23T06:12:14.130064Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2m for 1 cycle\n",
    "learn.fit_one_cycle(1, 5e-4, wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:29.618035Z",
     "start_time": "2019-09-23T06:14:28.275975Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.416068Z",
     "start_time": "2019-09-23T06:14:30.394064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('new_fastai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:14:30.390062Z",
     "start_time": "2019-09-23T06:14:29.622015Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:15:00.783777Z",
     "start_time": "2019-09-23T06:14:30.419064Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:48:28.754010Z",
     "start_time": "2019-09-23T05:48:28.695010Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T05:49:23.192015Z",
     "start_time": "2019-09-23T05:49:23.186013Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:100].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:53.245445Z",
     "start_time": "2019-09-23T06:20:52.962594Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[int(8.1e5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:20:54.105127Z",
     "start_time": "2019-09-23T06:20:54.098124Z"
    }
   },
   "outputs": [],
   "source": [
    "df.y.iloc[int(8.1e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:21:35.017074Z",
     "start_time": "2019-09-23T06:21:00.326024Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T06:22:24.129852Z",
     "start_time": "2019-09-23T06:22:24.099851Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.get_preds??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:17.953186Z",
     "start_time": "2019-09-25T10:41:17.948186Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_data_as_df(test_df, iteration, length):\n",
    "    return pd.DataFrame([test_df.head(length).iloc[iteration][:60].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:18.460048Z",
     "start_time": "2019-09-25T10:41:18.352054Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes in a DataFrame row [df] of shape (1,60) and adds 10 cross-sectional features.\n",
    "Returns a DataFrame of shape (1,70).\n",
    "'''\n",
    "def create_limited_features(df):\n",
    "    df.columns = [*askRateList, *askSizeList, *bidRateList, *bidSizeList]\n",
    "    # limited features\n",
    "    df['midRate'] = (df.bidRate0 + df.askRate0) / 2 # necessary for ohlc\n",
    "    df['bidAskVol'] = df.bidSize0 + df.askSize0 # necessary for ohlc\n",
    "    df['OIR'] = (df.bidSize0 - df.askSize0)/(df.bidSize0 + df.askSize0)\n",
    "    df['totalAskVol'] = df[askSizeList].sum(axis=1)\n",
    "    df['totalBidVol'] = df[bidSizeList].sum(axis=1)\n",
    "    df['OIR_total'] = (df.totalBidVol - df.totalAskVol)/(df.totalBidVol + df.totalAskVol)\n",
    "    \n",
    "    df['spread'] = df.askRate0 - df.bidRate0\n",
    "    df['bidAskVol'] = df.askSize0 + df.bidSize0\n",
    "    df['vwaBid'] = np.einsum('ij,ji->i', df[bidRateList], df[bidSizeList].T) / df[bidSizeList].sum(axis=1)\n",
    "    df['vwaAsk'] = np.einsum('ij,ji->i', df[askRateList], df[askSizeList].T) / df[askSizeList].sum(axis=1)\n",
    "    df['vwaBidDMid'] = df.midRate - df.vwaBid\n",
    "    df['vwaAskDMid'] = df.vwaAsk - df.midRate\n",
    "    df['diff_vwaBidAskDMid'] = df.vwaAskDMid - df.vwaBidDMid\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:19.035802Z",
     "start_time": "2019-09-25T10:41:19.030804Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Appends to [massive_df]=(many, >70) the DataFrame row [row]=(1,70). '''\n",
    "def append_to_df(massive_df, row):\n",
    "    try: row.index = [massive_df.index[-1] + timedelta(minutes=1)]\n",
    "    except IndexError: row.index = [datetime(1970,1,1)]\n",
    "    return massive_df.append(row, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:19.491407Z",
     "start_time": "2019-09-25T10:41:19.487366Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Adds time-dependent features. All features that use shift/diff must come here. '''\n",
    "def add_time_features(df, num):\n",
    "    return df[-num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:20.393760Z",
     "start_time": "2019-09-25T10:41:20.385768Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Creates more features based on resampled OHLC data. '''\n",
    "def add_resample_features(massive_df, resampled_df, num):\n",
    "    resampled_df_size = 15\n",
    "    leftovers = (massive_df.index[-1].value // 6e10 + 1) % num\n",
    "    def create_ohlc_features(df_mid, open_, high_, low_, close_, vol_):\n",
    "        df_mid = ta.add_others_ta(df_mid, close_)\n",
    "        return df_mid\n",
    "    row_ohlcv = massive_df.midRate.resample(str(num)+'Min').ohlc().tail(1)\n",
    "    row_ohlcv['vol'] = massive_df.bidAskVol.resample(str(num)+'Min').mean()\n",
    "    full_resampled = resampled_df.append(row_ohlcv, sort=False)\n",
    "    full_resampled = create_ohlc_features(full_resampled, 'open', 'high', 'low', 'close', 'vol')\n",
    "    if leftovers == 0:\n",
    "        resampled_df = resampled_df.append(row_ohlcv, sort=False).tail(resampled_df_size) # this adds a completed row_ohlcv\n",
    "    try: massive_df.drop(cols, axis=1, inplace=True)\n",
    "    except KeyError: pass\n",
    "    massive_df = massive_df.join(full_resampled[cols])\n",
    "    massive_df = massive_df.ffill().astype('float32') # no fillna because leaving rsi as nan is probably appropriate\n",
    "    return massive_df, resampled_df, full_resampled # full_resampled only for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:21.100300Z",
     "start_time": "2019-09-25T10:41:21.092325Z"
    }
   },
   "outputs": [],
   "source": [
    "''' This function takes in all features and makes a bounded prediction. '''\n",
    "def get_prediction(data, model):\n",
    "    X = data.replace([np.inf, -np.inf], np.nan).values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return np.clip(model.predict(np.atleast_2d(X_scaled)), -5, 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:21.800828Z",
     "start_time": "2019-09-25T10:41:21.791826Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' true_rlcvscore runs the submission functions on a test dataframe [test_df] taking the first [length] rows of [test_df].'''\n",
    "def true_rlcvscore(test_df, model, length):\n",
    "    num = 120\n",
    "    massive_df, resampled_df = pd.DataFrame(), pd.DataFrame()\n",
    "    predictions = []\n",
    "    log_data, resampled_data_list, full_resampled_data_list, massive_df_list = pd.DataFrame(), [], [], []  # for debug\n",
    "    for iteration in tqdm_notebook(range(length)):\n",
    "        base_row = get_next_data_as_df(test_df, iteration, length)\n",
    "        row = create_limited_features(base_row)\n",
    "        massive_df = append_to_df(massive_df, row)\n",
    "        massive_df = add_time_features(massive_df, num)\n",
    "        massive_df, resampled_df, full_resampled = add_resample_features(massive_df, resampled_df, num)\n",
    "        data = pd.DataFrame([massive_df.iloc[-1]])\n",
    "        log_data_row = data.copy() # for debug\n",
    "        prediction = get_prediction(data, model)\n",
    "        predictions.append(prediction)\n",
    "        log_data = log_data.append(log_data_row, sort=False) # for debug\n",
    "        resampled_data_list.append(resampled_df) # for debug\n",
    "        full_resampled_data_list.append(full_resampled) # for debug\n",
    "        massive_df_list.append(massive_df) # for debug\n",
    "    true_values = test_df.y.head(length)\n",
    "    score = r2d2(true_values, predictions)\n",
    "    print(f'{score:.4f}')\n",
    "    return predictions, score, log_data, true_values, resampled_data_list, full_resampled_data_list, massive_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:41:53.629443Z",
     "start_time": "2019-09-25T10:41:30.832439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54221202bebf469d96d7f6c45ba4639e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.7188\n"
     ]
    }
   ],
   "source": [
    "# takes 2m30s for 1000\n",
    "(test_predictions, test_score, log_data, true_values,\n",
    " resampled_data_list, full_resampled_data_list, massive_df_list) = true_rlcvscore(test_df, lgbm, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:10:29.469890Z",
     "start_time": "2019-09-25T10:10:29.459877Z"
    }
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series(limited_test.head(2000).others_dr, name='batch')\n",
    "s2 = pd.Series(log_data.others_dr, name='line-by-line')\n",
    "vals = pd.concat([s1,s2],axis=1); vals\n",
    "vals['difference'] = vals.batch - vals['line-by-line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:26:08.172974Z",
     "start_time": "2019-09-25T10:26:07.735972Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot(limited_test.head(2000).others_dr.values)\n",
    "plt.plot(log_data.others_dlr.values)\n",
    "plt.title('others_dlr', fontsize=20)\n",
    "plt.legend(['batch','line-by-line'], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''consider creating a model that takes in (1 to 120 rows) and predicts the final value. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T10:12:40.810165Z",
     "start_time": "2019-09-25T10:12:40.356168Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1, figsize=(15,8))\n",
    "plt.plot(vals.difference.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' the values are almost the same i.e. 3rd decimal place onwards. but the plot above says its from the first decimal place onwards'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''full_resampled is wrong --> log_data has wrong values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The most important thing now is to reconcile the dataframes in submission and in batch prediction. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-23T15:12:01.160601Z",
     "start_time": "2019-09-23T15:12:00.553603Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "plt.plot(test_predictions)\n",
    "plt.plot(true_values.values)\n",
    "plt.legend(['predictions', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T15:40:24.416970Z",
     "start_time": "2019-09-21T15:40:24.413968Z"
    }
   },
   "outputs": [],
   "source": [
    "# %lprun -f true_rlcvscore test_predictions, test_score = true_rlcvscore(test_df, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
